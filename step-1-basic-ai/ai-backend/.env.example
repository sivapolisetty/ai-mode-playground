# LLM Configuration - Choose one provider
LLM_PROVIDER=ollama  # or "openrouter"

# Ollama Configuration (Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:12b

# OpenRouter Configuration (Cloud)
OPENROUTER_API_KEY=your-api-key-here
OPENROUTER_MODEL=google/gemini-2.5-flash

# Traditional E-commerce API
TRADITIONAL_API_URL=http://localhost:3000

# Server Configuration
PORT=8001
LOG_LEVEL=DEBUG

# LangFuse Configuration (Optional - for observability)
LANGFUSE_SECRET_KEY=your-secret-key
LANGFUSE_PUBLIC_KEY=your-public-key
LANGFUSE_HOST=https://cloud.langfuse.com
# Or for self-hosted: LANGFUSE_HOST=http://localhost:3000